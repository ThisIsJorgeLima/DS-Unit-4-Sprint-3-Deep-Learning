{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
    "<br></br>\n",
    "<br></br>\n",
    "\n",
    "## *Data Science Unit 4 Sprint 3 Assignment 1*\n",
    "\n",
    "# Recurrent Neural Networks and Long Short Term Memory (LSTM)\n",
    "\n",
    "![Monkey at a typewriter](https://upload.wikimedia.org/wikipedia/commons/thumb/3/3c/Chimpanzee_seated_at_typewriter.jpg/603px-Chimpanzee_seated_at_typewriter.jpg)\n",
    "\n",
    "It is said that [infinite monkeys typing for an infinite amount of time](https://en.wikipedia.org/wiki/Infinite_monkey_theorem) will eventually type, among other things, the complete works of Wiliam Shakespeare. Let's see if we can get there a bit faster, with the power of Recurrent Neural Networks and LSTM.\n",
    "\n",
    "This text file contains the complete works of Shakespeare: https://www.gutenberg.org/files/100/100-0.txt\n",
    "\n",
    "Use it as training data for an RNN - you can keep it simple and train character level, and that is suggested as an initial approach.\n",
    "\n",
    "Then, use that trained RNN to generate Shakespearean-ish text. Your goal - a function that can take, as an argument, the size of text (e.g. number of characters or lines) to generate, and returns generated text of that size.\n",
    "\n",
    "Note - Shakespeare wrote an awful lot. It's OK, especially initially, to sample/use smaller data and parameters, so you can have a tighter feedback loop when you're trying to get things running. Then, once you've got a proof of concept - start pushing it more!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Import Statments:\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import requests \n",
    "\n",
    "from tensorflow.keras.callbacks import LambdaCallback\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "import random\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ltj1je1fp5rO"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5740053"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"https://www.gutenberg.org/files/100/100-0.txt\"\n",
    "r = requests.get(url)\n",
    "r.encoding = r.apparent_encoding\n",
    "data = r.text\n",
    "\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tm\\r\\nwork, (b) alteration, modification, or additions or deletions to any\\r\\nProject Gutenberg-tm work, and (c) any Defect you cause.\\r\\n\\r\\nSection 2. Information about the Mission of Project Gutenberg-tm\\r\\n\\r\\nProject Gutenberg-tm is synonymous with the free distribution of\\r\\nelectronic works in formats readable by the widest variety of computers\\r\\nincluding obsolete, old, middle-aged and new computers. It exists\\r\\nbecause of the efforts of hundreds of volunteers and donations from\\r\\npeople in all walks of life.\\r\\n\\r\\nVolunteers and financial support to provide volunteers with the\\r\\nassistance they need are critical to reaching Project Gutenberg-tm’s\\r\\ngoals and ensuring that the Project Gutenberg-tm collection will remain\\r\\nfreely available for generations to come. In 2001, the Project Gutenberg\\r\\nLiterary Archive Foundation was created to provide a secure and\\r\\npermanent future for Project Gutenberg-tm and future generations. To\\r\\nlearn more about the Project Gutenberg Literary Archive Foundation and\\r\\nhow your efforts and donations can help, see Sections 3 and 4 and the\\r\\nFoundation information page at www.gutenberg.org Section 3. Information\\r\\nabout the Project Gutenberg Literary Archive Foundation\\r\\n\\r\\nThe Project Gutenberg Literary Archive Foundation is a non profit\\r\\n501(c)(3) educational corporation organized under the laws of the state\\r\\nof Mississippi and granted tax exempt status by the Internal Revenue\\r\\nService. The Foundation’s EIN or federal tax identification number is\\r\\n64-6221541. Contributions to the Project Gutenberg Literary Archive\\r\\nFoundation are tax deductible to the full extent permitted by U.S.\\r\\nfederal laws and your state’s laws.\\r\\n\\r\\nThe Foundation’s principal office is in Fairbanks, Alaska, with the\\r\\nmailing address: PO Box 750175, Fairbanks, AK 99775, but its volunteers\\r\\nand employees are scattered throughout numerous locations. Its business\\r\\noffice is located at 809 North 1500 West, Salt Lake City, UT 84116,\\r\\n(801) 596-1887. Email contact links and up to date contact information\\r\\ncan be found at the Foundation’s web site and official page at\\r\\nwww.gutenberg.org/contact\\r\\n\\r\\nFor additional contact information:\\r\\n\\r\\n    Dr. Gregory B. Newby Chief Executive and Director gbnewby@pglaf.org\\r\\n\\r\\nSection 4. Information about Donations to the Project Gutenberg Literary\\r\\nArchive Foundation\\r\\n\\r\\nProject Gutenberg-tm depends upon and cannot survive without wide spread\\r\\npublic support and donations to carry out its mission of increasing the\\r\\nnumber of public domain and licensed works that can be freely\\r\\ndistributed in machine readable form accessible by the widest array of\\r\\nequipment including outdated equipment. Many small donations ($1 to\\r\\n$5,000) are particularly important to maintaining tax exempt status with\\r\\nthe IRS.\\r\\n\\r\\nThe Foundation is committed to complying with the laws regulating\\r\\ncharities and charitable donations in all 50 states of the United\\r\\nStates. Compliance requirements are not uniform and it takes a\\r\\nconsiderable effort, much paperwork and many fees to meet and keep up\\r\\nwith these requirements. We do not solicit donations in locations where\\r\\nwe have not received written confirmation of compliance. To SEND\\r\\nDONATIONS or determine the status of compliance for any particular state\\r\\nvisit www.gutenberg.org/donate\\r\\n\\r\\nWhile we cannot and do not solicit contributions from states where we\\r\\nhave not met the solicitation requirements, we know of no prohibition\\r\\nagainst accepting unsolicited donations from donors in such states who\\r\\napproach us with offers to donate.\\r\\n\\r\\nInternational donations are gratefully accepted, but we cannot make any\\r\\nstatements concerning tax treatment of donations received from outside\\r\\nthe United States. U.S. laws alone swamp our small staff.\\r\\n\\r\\nPlease check the Project Gutenberg Web pages for current donation\\r\\nmethods and addresses. Donations are accepted in a number of other ways\\r\\nincluding checks, online payments and credit card donations. To donate,\\r\\nplease visit: www.gutenberg.org/donate\\r\\n\\r\\nSection 5. General Information About Project Gutenberg-tm electronic\\r\\nworks.\\r\\n\\r\\nProfessor Michael S. Hart was the originator of the Project Gutenberg-tm\\r\\nconcept of a library of electronic works that could be freely shared\\r\\nwith anyone. For forty years, he produced and distributed Project\\r\\nGutenberg-tm eBooks with only a loose network of volunteer support.\\r\\n\\r\\nProject Gutenberg-tm eBooks are often created from several printed\\r\\neditions, all of which are confirmed as not protected by copyright in\\r\\nthe U.S. unless a copyright notice is included. Thus, we do not\\r\\nnecessarily keep eBooks in compliance with any particular paper edition.\\r\\n\\r\\nMost people start at our Web site which has the main PG search facility:\\r\\nwww.gutenberg.org\\r\\n\\r\\nThis Web site includes information about Project Gutenberg-tm, including\\r\\nhow to make donations to the Project Gutenberg Literary Archive\\r\\nFoundation, how to help produce our new eBooks, and how to subscribe to\\r\\nour email newsletter to hear about new eBooks.\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[-5000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode Data as Chars\n",
    "\n",
    "# Gather all text \n",
    "# Why? 1. See all possible characters 2. For training / splitting later\n",
    "text = \" \".join(data)\n",
    "\n",
    "# Unique Characters\n",
    "chars = list(set(text))\n",
    "\n",
    "# Lookup Tables\n",
    "char_int = {c:i for i, c in enumerate(chars)} \n",
    "int_char = {i:c for i, c in enumerate(chars)} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "107"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequences:  2296013\n"
     ]
    }
   ],
   "source": [
    "# Create the sequence data\n",
    "\n",
    "maxlen = 40\n",
    "step = 5\n",
    "\n",
    "encoded = [char_int[c] for c in text]\n",
    "\n",
    "sequences = [] # Each element is 40 chars long\n",
    "next_char = [] # One element for each sequence\n",
    "\n",
    "for i in range(0, len(encoded) - maxlen, step):\n",
    "    \n",
    "    sequences.append(encoded[i : i + maxlen])\n",
    "    next_char.append(encoded[i + maxlen])\n",
    "    \n",
    "print('sequences: ', len(sequences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[60,\n",
       " 15,\n",
       " 19,\n",
       " 15,\n",
       " 81,\n",
       " 15,\n",
       " 46,\n",
       " 15,\n",
       " 84,\n",
       " 15,\n",
       " 70,\n",
       " 15,\n",
       " 39,\n",
       " 15,\n",
       " 64,\n",
       " 15,\n",
       " 51,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 35,\n",
       " 15,\n",
       " 97,\n",
       " 15,\n",
       " 51,\n",
       " 15,\n",
       " 39,\n",
       " 15,\n",
       " 102,\n",
       " 15,\n",
       " 71,\n",
       " 15,\n",
       " 39,\n",
       " 15,\n",
       " 46,\n",
       " 15,\n",
       " 31,\n",
       " 15,\n",
       " 65,\n",
       " 15]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 20000\n",
    "# cut texts after this number of words (among top max_features most common words)\n",
    "maxlen = 80\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, None, 128)         2560000   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 2,691,713\n",
      "Trainable params: 2,691,713\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Embedding(max_features, 128))\n",
    "model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode Data as Chars\n",
    "\n",
    "# Gather all text \n",
    "# Why? 1. See all possible characters 2. For training / splitting later\n",
    "text = \" \".join(data)\n",
    "\n",
    "# Unique Characters\n",
    "chars = list(set(text))\n",
    "\n",
    "# Lookup Tables\n",
    "char_int = {c:i for i, c in enumerate(chars)} \n",
    "int_char = {i:c for i, c in enumerate(chars)} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "107"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create x & y\n",
    "\n",
    "x = np.zeros((len(sequences), maxlen, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sequences),len(chars)), dtype=np.bool)\n",
    "\n",
    "for i, sequence in enumerate(sequences):\n",
    "    for t, char in enumerate(sequence):\n",
    "        x[i,t,char] = 1\n",
    "        \n",
    "    y[i, next_char[i]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2296013, 40, 107), (2296013, 107))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2296013 samples\n",
      "Epoch 1/2\n",
      "2295968/2296013 [============================>.] - ETA: 0s - loss: 0.9590\n",
      "----- Generating text after Epoch: 0\n",
      "----- Generating with seed: \"g   A d o n i s   s i t t i n g   b y   \"\n",
      "    A d o n i s   s i t t i n g   b y   T r e e n g ? \n",
      " S C E N V A L \n",
      "     E n t e r   S T E R D ,   I \n",
      " _ l o o t i s ,   a s   h i s   s u d   f r o m   t h e   r i g h t   o f   m y \n",
      " T o   w e l l w e r y   e n t r e n o w ,   y o u r   p u c h   a n   y o u s   w a l l   o f   d o ’ t s , \n",
      "         A n d s t   t h e m . \n",
      "     L U C E N T O . \n",
      " I   b e a r d   y o u r   a r e   s u c h   l i v i l l ,   I ,   w a n k \n",
      "2296013/2296013 [==============================] - 2769s 1ms/sample - loss: 0.9590\n",
      "Epoch 2/2\n",
      "2296000/2296013 [============================>.] - ETA: 0s - loss: 0.8113\n",
      "----- Generating text after Epoch: 1\n",
      "----- Generating with seed: \" s h e   l o v ’ d   p r o v ’ d   m a d\"\n",
      " s h e   l o v ’ d   p r o v ’ d   m a d e ? \n",
      "     F U L S .   '"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jorge/opt/anaconda3/envs/U4-S1-NLP-DS10/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in log\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " T w i t i n g   I   j e c k e n e s s   t h e   d o o r ,   y i n k e d   i n t e r t e n c e   b e   b e g   o l d   d i r c h u r e n t   a r e   o n g e n ,   w i t h   m i g h t , \n",
      " A l a s l y   p o w e r   s t e r s a b e r   o f   e v e r   l i k e   o w r y ;   M a j e f t   p r o v e ;   a n d   h a v e   a l p o m e   t h a t   v a r e .   W h i c h   t h e r\n",
      "2296013/2296013 [==============================] - 2665s 1ms/sample - loss: 0.8113\n",
      "CPU times: user 4h 4min 8s, sys: 1h 8min 49s, total: 5h 12min 58s\n",
      "Wall time: 1h 30min 34s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x12e4e3d710>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# build the model: a single LSTM\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(maxlen, len(chars))))\n",
    "model.add(Dense(len(chars), activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "\n",
    "def sample(preds):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / 1\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)\n",
    "\n",
    "def on_epoch_end(epoch, _):\n",
    "    # Function invoked at end of each epoch. Prints generated text.\n",
    "    \n",
    "    print()\n",
    "    print('----- Generating text after Epoch: %d' % epoch)\n",
    "    \n",
    "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "    \n",
    "    generated = ''\n",
    "    \n",
    "    sentence = text[start_index: start_index + maxlen]\n",
    "    generated += sentence\n",
    "    \n",
    "    print('----- Generating with seed: \"' + sentence + '\"')\n",
    "    sys.stdout.write(generated)\n",
    "    \n",
    "    for i in range(400):\n",
    "        x_pred = np.zeros((1, maxlen, len(chars)))\n",
    "        for t, char in enumerate(sentence):\n",
    "            x_pred[0, t, char_int[char]] = 1\n",
    "            \n",
    "        preds = model.predict(x_pred, verbose=0)[0]\n",
    "        next_index = sample(preds)\n",
    "        next_char = int_char[next_index]\n",
    "        \n",
    "        sentence = sentence[1:] + next_char\n",
    "        \n",
    "        sys.stdout.write(next_char)\n",
    "        sys.stdout.flush()\n",
    "    print()\n",
    "\n",
    "\n",
    "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)\n",
    "\n",
    "# fit the model\n",
    "\n",
    "model.fit(x, y,\n",
    "          batch_size=32,\n",
    "          epochs=2,\n",
    "          callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zE4a4O7Bp5x1"
   },
   "source": [
    "# Resources and Stretch Goals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uT3UV3gap9H6"
   },
   "source": [
    "## Stretch goals:\n",
    "- Refine the training and generation of text to be able to ask for different genres/styles of Shakespearean text (e.g. plays versus sonnets)\n",
    "- Train a classification model that takes text and returns which work of Shakespeare it is most likely to be from\n",
    "- Make it more performant! Many possible routes here - lean on Keras, optimize the code, and/or use more resources (AWS, etc.)\n",
    "- Revisit the news example from class, and improve it - use categories or tags to refine the model/generation, or train a news classifier\n",
    "- Run on bigger, better data\n",
    "\n",
    "## Resources:\n",
    "- [The Unreasonable Effectiveness of Recurrent Neural Networks](https://karpathy.github.io/2015/05/21/rnn-effectiveness/) - a seminal writeup demonstrating a simple but effective character-level NLP RNN\n",
    "- [Simple NumPy implementation of RNN](https://github.com/JY-Yoon/RNN-Implementation-using-NumPy/blob/master/RNN%20Implementation%20using%20NumPy.ipynb) - Python 3 version of the code from \"Unreasonable Effectiveness\"\n",
    "- [TensorFlow RNN Tutorial](https://github.com/tensorflow/models/tree/master/tutorials/rnn) - code for training a RNN on the Penn Tree Bank language dataset\n",
    "- [4 part tutorial on RNN](http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-1-introduction-to-rnns/) - relates RNN to the vanishing gradient problem, and provides example implementation\n",
    "- [RNN training tips and tricks](https://github.com/karpathy/char-rnn#tips-and-tricks) - some rules of thumb for parameterizing and training your RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "U4S1DS10 (Python 3.7)",
   "language": "python",
   "name": "u4-s1-nlp-ds10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
